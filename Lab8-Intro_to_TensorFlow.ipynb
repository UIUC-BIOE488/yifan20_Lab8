{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow\n",
    "------------------\n",
    "### Contents:\n",
    "- Tensors\n",
    "    - Rank, shape, converting to/from NumPy, indexing\n",
    "    - Variables\n",
    "    - Placement on CPU/GPU device\n",
    "- TensorFlow: Basic tensor operations and computation/dataflow graphs\n",
    "    - Operations - tf.math, tf.linalg, tf.random\n",
    "    - Eager execution\n",
    "    - Computation graphs\n",
    "    - Graph execution\n",
    "        - TF1.x: sessions\n",
    "        - TF2.x: functions\n",
    "    - Differences between TF1.x and TF2.x\n",
    "- TF datasets\n",
    "    - Creating TF datasets\n",
    "    - Passing datasets through a function\n",
    "- Automatic differentiation\n",
    "    - tf.GradientTape\n",
    "- 2D convolutions (with fixed filters)\n",
    "    - Using the raw tf convolution operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Make sure you have a GPU available for this session! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "# [Section] Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # may take ~10-15s\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does a 3D/rank-3 tensor look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tensor Rank 3](./resources/tensor_rank_3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_3_tensor = tf.constant([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],])\n",
    "\n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What properties does a tensor have?\n",
    "\n",
    "**Shape:** The length (number of elements) of each of the axes of a tensor.\n",
    "\n",
    "**Rank:** Number of tensor axes. A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n",
    "\n",
    "**Axis or Dimension:** A particular dimension of a tensor.\n",
    "\n",
    "**Size:** The total number of items in the tensor, the product of the shape vector's elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Type of every element:\", rank_3_tensor.dtype)\n",
    "print(\"Number of axes:\", rank_3_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_3_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\", rank_3_tensor.shape[0])\n",
    "print(\"Elements along the last axis of tensor:\", rank_3_tensor.shape[-1])\n",
    "print(\"Total number of elements:\", int(tf.size(rank_3_tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does a 4D/rank-4 tensor look like?\n",
    "\n",
    "In tensorflow, image data is typically assumed to be 4D i.e. rank 4.\n",
    "\n",
    "![Tensor Rank 4](./resources/tensor_rank_4.jpg)\n",
    "\n",
    "\n",
    "![Tensor Rank 4 Meaning](./resources/tensor_rank_4_meaning.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_4_tensor = tf.zeros([3, 2, 4, 5])\n",
    "\n",
    "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of axes:\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements (3*2*4*5): \", int(tf.size(rank_4_tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating the shape of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
    "print(tf.reshape(rank_3_tensor, [3, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to/from NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, a TensorFlow ```tensor``` is very similar to a Numpy ```ndarray```.\n",
    "\n",
    "**The key difference between tensors and NumPy arrays is that tensors have accelerator support like GPU and TPU and are immutable (i.e. cannot be updated once created).** (A special type of tensor, called variable, can be assgined new values. We will see them later in the lab.)\n",
    "\n",
    "**Most of the time, tf.Tensor and np.ndarray can be automatically inter-converted:**\n",
    "\n",
    "- TensorFlow operations automatically convert NumPy ndarrays to Tensors.\n",
    "- NumPy operations automatically convert Tensors to NumPy ndarrays.\n",
    "\n",
    "If needed, you can explicitly convert tensors to NumPy ndarrays using their .numpy() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically:\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "print(\"Vice-versa, NumPy operations convert Tensors to numpy arrays automatically:\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array:\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more: https://www.kdnuggets.com/2022/05/everything-need-know-tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing - single-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
    "print(rank_1_tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
    "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
    "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing - multi-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to be specific, you can set the dtype (see below) at creation time\n",
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "print(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get row and column tensors\n",
    "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more: https://www.tensorflow.org/guide/tensor_slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables - a special type of tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A TensorFlow ```variable``` is the recommended way to represent shared, persistent state your program manipulates. Variables are created and tracked via the ```tf.Variable``` class. A ```tf.Variable``` represents a tensor whose value can be changed through various operations. A variable looks and acts like a tensor, and, in fact, is a data structure backed by a ```tf.Tensor```. Like tensors, they have a dtype and a shape, and can be exported to NumPy. Variables can also be named which can help you track and debug them.\n",
    "\n",
    "**Remember - A tensor can be assigned value only once and cannot be updated. TF tensors, like python numbers and strings, are immutable and can only be created new. In case your objective is to update the value of the tensor, then you need to use a ```variable```.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "my_variable = tf.Variable(my_tensor, name=\"ABCD\")\n",
    "\n",
    "print(my_variable)\n",
    "print(\"Shape: \", my_variable.shape)\n",
    "print(\"DType: \", my_variable.dtype)\n",
    "print(\"As NumPy: \", my_variable.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try editing the value of the ```constant``` tensor (Errors are expected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor[:,0] = [-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor.assign([[-1, -2],[-3, -4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's try editing the value of the ```variable``` tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_variable.assign([[-1, -2],[-3, -4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific operations allow you to read and modify the values of this tensor. Higher level libraries like ```tf.keras``` use ```tf.Variable``` to store model parameters. Read more - https://www.tensorflow.org/guide/variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placing tensors on devices (CPUs, GPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better performance, TensorFlow will attempt to place tensors and variables on the fastest device compatible with its dtype. This means most variables are placed on a GPU if one is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"Is there a GPU available: \"),\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "print(\"Is the Tensor on GPU #0:  \"),\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to set the location of a variable or tensor on one device and do the computation on another device. This will introduce delay, as data needs to be copied between the devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('CPU:0'):\n",
    "    a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.Variable([[1.0, 2.0, 3.0]])\n",
    "    print(a.device, b.device)\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "    # Element-wise multiply\n",
    "    k = a * b\n",
    "    print(k.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Because ```tf.config.set_soft_device_placement``` is turned on by default, even if you run this code on a device without a GPU, it will still run. The operations will happen on the CPU.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more: https://www.tensorflow.org/guide/tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "# [Section] Tensorflow: Operations on Tensors and Dataflow Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is a machine learning framework with built-in optimizations for GPU computation with Nvidia CUDA. You can build, train, test your deep learning models, or even just perform basic tensor operations with it.\n",
    "\n",
    "The name TensorFlow reveals the mechanisms behind it: data is represented as \"tensors\", and the computations are performed in graph models. Think of it as a mathmetical graph consisting of nodes and edges; the data flows through the edges and computation is performed on the nodes.\n",
    "\n",
    "![Data Flowing through a Deep Neural Network](./resources/neural_network_flow.gif)\n",
    "\n",
    "<!-- What's a tensor in mathmatical terms? [Watch this video](https://www.youtube.com/watch?v=f5liqUk0ZTw&t=623s)(12:21) for an intuitive explanation.  (Optional) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "print(tf.matmul([[1]], [[2, 3]]))\n",
    "\n",
    "# Operator overloading is also supported\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries of standard operations such as math, linear algebra, statistics:\n",
    "- https://www.tensorflow.org/api_docs/python/tf/math\n",
    "- https://www.tensorflow.org/api_docs/python/tf/linalg\n",
    "- https://www.tensorflow.org/api_docs/python/tf/random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, all computations have been run _\"eagerly\"_. This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python. **The default mode of execution in TF2.x is eager where operations are evaluated and results are returned immediately.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benefits** of eager execution:\n",
    "- Easier debugging: simplifies the model building experience, easy to test\n",
    "- Intuitive for beginners: natural control flow, execution is intuitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downside** of eager execution - slower than the other available mode of execution (graph execution). Since eager execution runs all operations one-by-one in Python, it cannot take advantage of potential acceleration opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs, or ```tf.Graph``` objects, are special data structures with ```tf.Operation``` and ```tf.Tensor``` objects. While ```tf.Operation``` objects represent computational units, ```tf.Tensor``` objects represent data units. A computational graph (or graph in short) is a series of TensorFlow operations arranged into a graph of nodes. Basically, it means a graph is just an arrangement of nodes that represent the operations in your model.\n",
    "\n",
    "Let's look at an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Graph example](./resources/comp_graph_example_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise] Write tensorflow code such that the operations yield the computation graph shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see how to visualize these graphs using ```TensorBoard``` in the next lab. Read more: https://www.tensorflow.org/guide/intro_to_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph execution extracts tensor computations from Python and builds an efficient graph before evaluation. In graph execution, evaluation of all the operations happens only after weâ€™ve called our program entirely.\n",
    "\n",
    "**Benefits** of graph execution:\n",
    "- Graphs can be saved, run, and restored without original Python code, which provides extra flexibility for cross-platform applications. With a graph, you can take advantage of your model in mobile, embedded, and backend environment where Python is unavailable.\n",
    "- Graphs are easy to optimize. They allow compiler-level transformations such as statistical inference of tensor values with constant folding, distribute sub-parts of operations between threads and devices (an advanced level distribution), and simplify arithmetic operations.\n",
    "\n",
    "\n",
    "**Downsides** of graph execution:\n",
    "- difficult-to-learn, difficult-to-test, and non-intuitive for beginners\n",
    "- may be slower for small computations due to graph construction/optimization overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The default mode of execution in TF2.x is eager where operations are evaluated immediately. This is in contrast to graph execution where the computational graph is constructed for later evaluation.** Let's now see how we can perform graph execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TFv1.x: Using tf sessions**\n",
    "\n",
    "A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "\n",
    "a = tf.constant([[10,10],[11.,1.]])\n",
    "x = tf.constant([[1.,0.],[0.,1.]])\n",
    "b = tf.constant(12.)\n",
    "y = tf.matmul(a, x) + b\n",
    "\n",
    "# Intialize the Session\n",
    "# Note -Sessions are depracated in TensorFlow 2.0 in 2019. For backward compatibility, you can still access them through tf.compat.v1.Session()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### *** NEED TO RESTART KERNEL HERE ***\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TFv2.x: Using tf functions** \n",
    "\n",
    "You create and run a graph in TensorFlow by using ```tf.function```, either as a direct call or as a decorator. ```tf.function``` takes a regular function as input and returns a Function. A Function is a Python callable that builds TensorFlow graphs from the Python function. You use a Function in the same way as its Python equivalent. Using ```tf.function``` allows you to switch from eager execution to graph execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([[10,10],[11.,1.]])\n",
    "x = tf.constant([[1.,0.],[0.,1.]])\n",
    "b = tf.constant(12.)\n",
    "y = tf.matmul(a, x) + b\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def a_regular_function(a, x, b):\n",
    "    y = tf.matmul(a, x) + b\n",
    "    return y\n",
    "\n",
    "# Alternatively, use the @tf.function wrapper\n",
    "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
    "\n",
    "# Make some tensors.\n",
    "a = tf.constant([[10,10],[11.,1.]])\n",
    "x = tf.constant([[1.,0.],[0.,1.]])\n",
    "b = tf.constant(12.)\n",
    "\n",
    "# Call a `Function` like a Python function.\n",
    "y = a_function_that_uses_a_graph(a, x, b)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more: https://www.tensorflow.org/guide/intro_to_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ** CAUTION ** - TFv1.x vs TFv2.x\n",
    "- https://blog.tensorflow.org/2019/02/effective-tensorflow-20-best-practices.html\n",
    "- https://www.tensorflow.org/guide/effective_tf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, graphs are extremely useful and let your TensorFlow run fast, run in parallel, and run efficiently on multiple devices. **However, you still want to define your machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "# [Section] TF Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tf.data.Dataset``` represents a sequence of elements, in which each element consists of one or more components. For example, in an image data pipeline, an element might be a single data point, with a pair of tensor components representing the image (x) and its output label/value (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tf datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])\n",
    "for elem in dataset:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# a dataset with 5 samples - each sample contains three elements (a, x, b)\n",
    "a = tf.constant(np.random.rand(5, 2, 2))\n",
    "x = tf.constant(np.random.rand(5, 2, 2))\n",
    "b = tf.constant(np.random.rand(5, 1))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((a, x, b))\n",
    "print(dataset)\n",
    "print(dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Dataset.element_spec``` property above allows you to inspect the type of each element component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, x, b in dataset:\n",
    "    print(a, x, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running datasets through a function (computation graph)\n",
    "\n",
    "Let's see how we can run the (a, x, b) dataset above through our ```a_function_that_uses_a_graph``` function to get the results ```y``` for each sample in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dataset.map(a_function_that_uses_a_graph)\n",
    "for y in results:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more: https://www.tensorflow.org/guide/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "# [Section] Automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tape - Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tf.GradientTape``` is used for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually ```tf.Variables```. TensorFlow \"records\" relevant operations executed inside the context of a ```tf.GradientTape``` onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\n",
    "\n",
    "Once you've recorded some operations, use ```GradientTape.gradient(target, sources)``` to calculate the gradient of some target (often a loss) relative to some source (often the model's variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    x = tf.Variable(5.0)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        y = x**2\n",
    "    \n",
    "    # dy = 2x * dx\n",
    "    dy_dx = tape.gradient(y, x)\n",
    "    dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tape - Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "    b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "    x = [[1., 2., 3.]]\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        y = x @ w + b\n",
    "        loss = tf.reduce_mean(y**2)\n",
    "        \n",
    "    [dl_dw, dl_db] = tape.gradient(loss, [w, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient with respect to each source has the shape of the source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w.shape)\n",
    "print(dl_dw.shape)\n",
    "print(\"-------\")\n",
    "print(b.shape)\n",
    "print(dl_db.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although variables are important for differentiation, some variables will not need to be differentiated. You can turn off gradients for a variable by setting trainable to false at creation. An example of a variable that would not need gradients is a step counter: ```step_counter = tf.Variable(1, trainable=False)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more: https://www.tensorflow.org/guide/autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "# [Section] 2D Convolutions in TF (with fixed filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img.imread(\"./resources/brain.png\")[:,:,:3]\n",
    "print(image.shape)\n",
    "image = color.rgb2gray(image)\n",
    "print(image.shape)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the raw convolution operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw convolution operation can be found at https://www.tensorflow.org/versions/r2.8/api_docs/python/tf/raw_ops/Conv2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_x = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "sobel_x = sobel_x.reshape((3, 3, 1, 1))\n",
    "\n",
    "sobel_y = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_y = sobel_y.reshape((3, 3, 1, 1))\n",
    "\n",
    "image = image.reshape(1, 557, 481, 1)\n",
    "\n",
    "result_x = tf.raw_ops.Conv2D(\n",
    "    input=image,\n",
    "    filter=sobel_x,\n",
    "    strides=[1,1,1,1],\n",
    "    padding=\"SAME\",\n",
    "    use_cudnn_on_gpu=True,\n",
    "    data_format='NHWC', # (1, 557, 481, 1)\n",
    ")\n",
    "\n",
    "result_y = tf.raw_ops.Conv2D(\n",
    "    input=image,\n",
    "    filter=sobel_y,\n",
    "    strides=[1,1,1,1],\n",
    "    padding=\"SAME\",\n",
    "    use_cudnn_on_gpu=True,\n",
    "    data_format='NHWC', # (1, 557, 481, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(result_x[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(result_y[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "# References:\n",
    "- https://www.kdnuggets.com/2022/05/everything-need-know-tensors.html\n",
    "- https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/\n",
    "- https://www.tensorflow.org/tutorials/customization/basics\n",
    "- https://stackabuse.com/understanding-tensorflows-tffunction-decorator/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
